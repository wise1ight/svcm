{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7be8a2b",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8d9309f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kuvh\\.conda\\envs\\cuda\\lib\\site-packages\\torch_lr_finder\\lr_finder.py:5: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from glob import glob\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from torch_lr_finder import LRFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad1c85b",
   "metadata": {},
   "source": [
    "# General helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdba3f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_all(model_params):\n",
    "    for param in model_params:\n",
    "        param.requires_grad = False\n",
    "        \n",
    "def unfreeze_all(model_params):\n",
    "    for param in model_params:\n",
    "        param.requires_grad = True\n",
    "        \n",
    "def get_trainable(model_params):\n",
    "    return (p for p in model_params if p.requires_grad)\n",
    "\n",
    "def load_image(filename) :\n",
    "    img = Image.open(filename)\n",
    "    img = img.convert('RGB')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11fade4",
   "metadata": {},
   "source": [
    "# Load the Resnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49205763",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\kuvh/.cache\\torch\\hub\\pytorch_vision_main\n",
      "C:\\Users\\kuvh\\.conda\\envs\\cuda\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kuvh\\.conda\\envs\\cuda\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = torch.hub.load('pytorch/vision', 'resnet34', pretrained=True)\n",
    "resnet.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b758f853",
   "metadata": {},
   "source": [
    "# Get the data and do preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be37128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob('./datasets/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf6c9f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'7000Fourth', '7000Fifth', '7000Second', '7000First', '7000Third'}\n"
     ]
    }
   ],
   "source": [
    "classes = set()\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load the images and get the classnames from the image path\n",
    "for image in filenames:\n",
    "    class_name = image.rsplit(\"\\\\\", 1)[1].rsplit('_', 1)[0]\n",
    "    classes.add(class_name)\n",
    "    img = load_image(image)\n",
    "\n",
    "    data.append(img)\n",
    "    labels.append(class_name)\n",
    "    \n",
    "    \n",
    "print(classes)\n",
    "\n",
    "# convert classnames to indices\n",
    "class2idx = {cl: idx for idx, cl in enumerate(classes)}        \n",
    "labels = torch.Tensor(list(map(lambda x: class2idx[x], labels))).long()\n",
    "\n",
    "data = list(zip(data, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "195f85c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VehicleDataset(Dataset):\n",
    "    \"Dataset to serve individual images to our model\"\n",
    "    \n",
    "    def __init__(self, data, transforms=None):\n",
    "        self.data = data\n",
    "        self.len = len(data)\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img, label = self.data[index]\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "            \n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "# Since the data is not split into train and validation datasets we have to \n",
    "# make sure that when splitting between train and val that all classes are represented in both\n",
    "class Databasket():\n",
    "    \"Helper class to ensure equal distribution of classes in both train and validation datasets\"\n",
    "    \n",
    "    def __init__(self, data, num_cl, val_split=0.2, train_transforms=None, val_transforms=None):\n",
    "        class_values = [[] for x in range(num_cl)]\n",
    "        \n",
    "        # create arrays for each class type\n",
    "        for d in data:\n",
    "            class_values[d[1].item()].append(d)\n",
    "            \n",
    "        self.train_data = []\n",
    "        self.val_data = []\n",
    "        \n",
    "        # put (1-val_split) of the images of each class into the train dataset\n",
    "        # and val_split of the images into the validation dataset\n",
    "        for class_dp in class_values:\n",
    "            split_idx = int(len(class_dp)*(1-val_split))\n",
    "            self.train_data += class_dp[:split_idx]\n",
    "            self.val_data += class_dp[split_idx:]\n",
    "            \n",
    "        self.train_ds = VehicleDataset(self.train_data, transforms=train_transforms)\n",
    "        self.val_ds = VehicleDataset(self.val_data, transforms=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32ac263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Apply transformations to the train dataset\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# apply the same transformations to the validation set, with the exception of the\n",
    "# randomized transformation. We want the validation set to be consistent\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "])\n",
    "\n",
    "databasket = Databasket(data, len(classes), val_split=0.2, train_transforms=train_transforms, val_transforms=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d9d64e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_types = (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)\n",
    "\n",
    "class AdaptiveConcatPool2d(nn.Module):\n",
    "    \"Layer that concats `AdaptiveAvgPool2d` and `AdaptiveMaxPool2d`.\"\n",
    "    def __init__(self, sz=None):\n",
    "        \"Output will be 2*sz or 2 if sz is None\"\n",
    "        super(AdaptiveConcatPool2d, self).__init__()\n",
    "        self.output_size = sz or 1\n",
    "        self.ap = nn.AdaptiveAvgPool2d(self.output_size)\n",
    "        self.mp = nn.AdaptiveMaxPool2d(self.output_size)\n",
    "\n",
    "    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)\n",
    "\n",
    "def head_blocks(in_dim, p, out_dim, activation=None):\n",
    "    \"Basic Linear block\"\n",
    "    layers = [\n",
    "        nn.BatchNorm1d(in_dim),\n",
    "        nn.Dropout(p),\n",
    "        nn.Linear(in_dim, out_dim)\n",
    "    ]\n",
    "    \n",
    "    if activation is not None:\n",
    "        layers.append(activation)\n",
    "        \n",
    "    return layers       \n",
    "    \n",
    "def create_head(nf, nc, bn_final=False):\n",
    "    \"Model head that takes in 'nf' features and outputs 'nc' classes\"\n",
    "    pool = AdaptiveConcatPool2d()\n",
    "    layers = [pool, nn.Flatten()]\n",
    "    layers += head_blocks(nf, 0.25, 512, nn.ReLU(inplace=True))\n",
    "    layers += head_blocks(512, 0.5, nc)\n",
    "    \n",
    "    if bn_final:\n",
    "        layers.append(nn.BatchNorm1d(nc, momentum=0.01))\n",
    "    \n",
    "    return nn.Sequential(*layers)\n",
    "    \n",
    "def requires_grad(layer):\n",
    "    \"Determines whether 'layer' requires gradients\"\n",
    "    ps = list(layer.parameters())\n",
    "    if not ps: return None\n",
    "    return ps[0].requires_grad\n",
    "\n",
    "def cnn_model(model, nc, bn_final=False, init=nn.init.kaiming_normal_):\n",
    "    \"Creates a model using a pretrained 'model' and appends a new head to it with 'nc' outputs\"\n",
    "    \n",
    "    # remove dense and freeze everything\n",
    "    body = nn.Sequential(*list(model.children())[:-2])\n",
    "    head = create_head(1024, nc, bn_final)\n",
    "    \n",
    "    model = nn.Sequential(body, head)\n",
    "    \n",
    "    # freeze the resnet34 base of the model\n",
    "    freeze_all(model[0].parameters())\n",
    "    \n",
    "    # initialize the weights of the head\n",
    "    for child in model[1].children():\n",
    "        if isinstance(child, nn.Module) and (not isinstance(child, bn_types)) and requires_grad(child): \n",
    "            init(child.weight)\n",
    "    \n",
    "    return model\n",
    "\n",
    "num_classes = len(classes)\n",
    "model = cnn_model(resnet, num_classes, bn_final=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f40473e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): AdaptiveConcatPool2d(\n",
       "      (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "      (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "    )\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.25, inplace=False)\n",
       "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.5, inplace=False)\n",
       "    (8): Linear(in_features=512, out_features=5, bias=True)\n",
       "    (9): BatchNorm1d(5, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16919f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = list(range(len(databasket.train_ds)))\n",
    "test_indices = list(range(len(databasket.val_ds)))\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "# Basic dataloader to retrieve mini-batches from the datasets\n",
    "train_loader = DataLoader(databasket.train_ds, batch_size=64, sampler=train_sampler, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(databasket.val_ds, batch_size=64, sampler=test_sampler, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c61fc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# We don't actually use the learning rate here. It's set to 1e-7 so that the LR Finder\n",
    "# starts at 1e-7\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-7,  weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dede2371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:17<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate search finished. See the graph with {finder_name}.plot()\n",
      "LR suggestion: steepest gradient\n",
      "Suggested LR: 2.02E-03\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<Axes: xlabel='Learning rate', ylabel='Loss'>, 0.0020184091545236674)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# used to find the ideal LR for our model training\n",
    "lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
    "lr_finder.range_test(train_loader, end_lr=3, num_iter=100)\n",
    "lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfe3fedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A one cycle LR scheduler (https://arxiv.org/abs/1708.07120)\n",
    "# max_lr is derived from the lr_finder plot\n",
    "# epochs must match the amount of epochs you will run\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=5e-2, pct_start=0.3, steps_per_epoch=len(train_loader), epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a58a7003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Accuracy: 98.02 percent, Validation Accuracy: 55.56 percent, Train Loss: 0.05487476475536823, Validation Loss: 13.10173225402832\n",
      "Epoch 1: Train Accuracy: 100.00 percent, Validation Accuracy: 55.56 percent, Train Loss: 0.0014053554914426059, Validation Loss: 10.570838928222656\n",
      "Epoch 2: Train Accuracy: 100.00 percent, Validation Accuracy: 55.56 percent, Train Loss: 0.004546144977211952, Validation Loss: 9.234745979309082\n",
      "Epoch 3: Train Accuracy: 100.00 percent, Validation Accuracy: 55.56 percent, Train Loss: 0.008384269254747778, Validation Loss: 8.148802757263184\n",
      "Epoch 4: Train Accuracy: 100.00 percent, Validation Accuracy: 55.56 percent, Train Loss: 0.005506520392373204, Validation Loss: 7.468900203704834\n",
      "Epoch 5: Train Accuracy: 100.00 percent, Validation Accuracy: 55.56 percent, Train Loss: 0.008854831103235483, Validation Loss: 6.951882362365723\n",
      "Epoch 6: Train Accuracy: 100.00 percent, Validation Accuracy: 55.56 percent, Train Loss: 0.007405975600704551, Validation Loss: 6.565104961395264\n",
      "Epoch 7: Train Accuracy: 100.00 percent, Validation Accuracy: 51.85 percent, Train Loss: 0.0019091700087301433, Validation Loss: 6.281381130218506\n",
      "Epoch 8: Train Accuracy: 100.00 percent, Validation Accuracy: 55.56 percent, Train Loss: 0.006530523533001542, Validation Loss: 5.921393394470215\n",
      "Epoch 9: Train Accuracy: 100.00 percent, Validation Accuracy: 55.56 percent, Train Loss: 0.0016451282135676593, Validation Loss: 5.679706573486328\n",
      "Epoch 10: Train Accuracy: 100.00 percent, Validation Accuracy: 51.85 percent, Train Loss: 0.0014857143542030826, Validation Loss: 5.448638439178467\n",
      "Epoch 11: Train Accuracy: 100.00 percent, Validation Accuracy: 55.56 percent, Train Loss: 0.0037164594687055796, Validation Loss: 5.286853790283203\n",
      "Epoch 12: Train Accuracy: 99.01 percent, Validation Accuracy: 55.56 percent, Train Loss: 0.02381795202381909, Validation Loss: 5.12127685546875\n",
      "Epoch 13: Train Accuracy: 100.00 percent, Validation Accuracy: 55.56 percent, Train Loss: 0.0007942488591652364, Validation Loss: 4.950820446014404\n",
      "Epoch 14: Train Accuracy: 100.00 percent, Validation Accuracy: 55.56 percent, Train Loss: 0.003680426860228181, Validation Loss: 4.833934783935547\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "model.to(device)\n",
    "\n",
    "def train(epochs, scheduler, optimizer, model):\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        n_correct = 0\n",
    "        \n",
    "        # use dropouts and batchnorms\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            inputs, labels = batch\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            #zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        train_acc = 100. * n_correct / len(databasket.train_ds)\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        \n",
    "        n_val_correct = 0\n",
    "        val_loss = 0\n",
    "        \n",
    "        # disable batchnorm and dropouts\n",
    "        model.eval()\n",
    "        # don't calculate gradient\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                inputs, labels = batch\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                val_loss = criterion(outputs, labels).item()\n",
    "\n",
    "                n_val_correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "                \n",
    "                \n",
    "                \n",
    "        val_acc = 100. * n_val_correct / len(databasket.val_ds)\n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "        print('Epoch %s: Train Accuracy: %.2f percent, Validation Accuracy: %.2f percent, Train Loss: %s, Validation Loss: %s' \n",
    "              % (epoch, train_acc, val_acc, train_loss, val_loss))\n",
    "        \n",
    "train(15, scheduler, optimizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4710e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': 15,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, './models/vehicle_1.pt')\n",
    "example = torch.rand(1, 3, 224, 224)\n",
    "model.cpu()\n",
    "traced_script_module = torch.jit.trace(model, example)\n",
    "traced_script_module_optimized = optimize_for_mobile(traced_script_module)\n",
    "traced_script_module_optimized._save_for_lite_interpreter('./models/vehicle_lite_1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b2ad81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unfreeze_all(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f67ad4a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam([\n\u001b[0;32m      3\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m: model[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1e-7\u001b[39m},\n\u001b[0;32m      4\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m: model[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1e-7\u001b[39m}\n\u001b[0;32m      5\u001b[0m     ],  weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[0;32m      6\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mOneCycleLR(optimizer, max_lr\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1e-6\u001b[39m,\u001b[38;5;241m1e-3\u001b[39m), pct_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, steps_per_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader), epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 20\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epochs, scheduler, optimizer, model)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#zero the parameter gradients\u001b[39;00m\n\u001b[0;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 20\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     23\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\.conda\\envs\\cuda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\cuda\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\.conda\\envs\\cuda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\cuda\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\.conda\\envs\\cuda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\cuda\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\cuda\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "# discriminative learning rate for fine tuning\n",
    "optimizer = optim.Adam([\n",
    "        {\"params\": model[0].parameters(), \"lr\": 1e-7},\n",
    "        {\"params\": model[1].parameters(), \"lr\": 1e-7}\n",
    "    ],  weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=(1e-6,1e-3), pct_start=0.8, steps_per_epoch=len(train_loader), epochs=5)\n",
    "train(5, scheduler, optimizer, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
